{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제 1\n",
    "### 은닉층 1개의 노드를 1개부터 10개 까지 임의의 노드개수를 선정해서 XOR 문제를 해결하고자 한다. \n",
    "### 코드의 범용성(versatility)을 높이기 위해서 Logicgate 클래스의 어떤 부분을 변경하는 것이 좋은가? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def derivative(f,var):\n",
    "    delta_x=1e-5\n",
    "    grad=np.zeros_like(var)\n",
    "\n",
    "    it=np.nditer(var,flags=['multi_index'], op_flags=['readwrite'])\n",
    "\n",
    "    while not it.finished:\n",
    "        idx=it.multi_index\n",
    "\n",
    "        tmp_val=var[idx]\n",
    "        var[idx]=float(tmp_val)+delta_x\n",
    "        fx1=f(var) \n",
    "\n",
    "        var[idx]=float(tmp_val)-delta_x\n",
    "        fx2=f(var)\n",
    "        grad[idx]=(fx1-fx2)/(2*delta_x)     \n",
    "\n",
    "        var[idx]=tmp_val\n",
    "        it.iternext()\n",
    "    \n",
    "    return grad\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "class LogicGate:\n",
    "    def __init__(self, gate_name, xdata, tdata, node_num): # 문제 1 : 은닉층의 node 개수를 받는 argument(=node_num)를 추가함.\n",
    "        self.name=gate_name\n",
    "        self.xdata=xdata.reshape(4,2)\n",
    "        self.tdata=tdata.reshape(4,1)\n",
    "\n",
    "        self.W2=np.random.rand(2,node_num)\n",
    "        self.b2=np.random.rand(node_num)\n",
    "\n",
    "        self.W3=np.random.rand(node_num,1)\n",
    "        self.b3=np.random.rand(1)\n",
    "\n",
    "        self.learning_rate=1e-2\n",
    "\n",
    "    def feed_forward(self):\n",
    "        delta=1e-5\n",
    "        z2=np.dot(self.xdata,self.W2)+self.b2\n",
    "        a2=sigmoid(z2)\n",
    "        z3=np.dot(a2,self.W3)+self.b3\n",
    "        y=a3=sigmoid(z3)\n",
    "        return -np.sum(self.tdata*np.log(y+delta)+(1-self.tdata)*np.log((1-y)+delta))\n",
    "\n",
    "    def loss_val(self):\n",
    "        delta=1e-5\n",
    "        z2=np.dot(self.xdata,self.W2)+self.b2\n",
    "        a2=sigmoid(z2)\n",
    "        z3=np.dot(a2,self.W3)+self.b3\n",
    "        y=a3=sigmoid(z3)\n",
    "        return -np.sum(self.tdata*np.log(y+delta)+(1-self.tdata)*np.log((1-y)+delta))\n",
    "\n",
    "    def train(self):\n",
    "        f=lambda x:self.feed_forward()\n",
    "        print(\"Initial loss val= \", self.loss_val())\n",
    "\n",
    "        for step in range(20001):\n",
    "            self.W2-=self.learning_rate*derivative(f,self.W2)\n",
    "            self.b2-=self.learning_rate*derivative(f,self.b2)\n",
    "\n",
    "            self.W3-=self.learning_rate*derivative(f,self.W3)\n",
    "            self.b3-=self.learning_rate*derivative(f,self.b3)\n",
    "\n",
    "            if step%1000==0:\n",
    "                print(\"step= \",step,\" loss value= \",self.loss_val())\n",
    "    \n",
    "    def predict(self,input_data):\n",
    "        z2=np.dot(input_data,self.W2)+self.b2\n",
    "        a2=sigmoid(z2)\n",
    "        z3=np.dot(a2,self.W3)+self.b3\n",
    "        y=a3=sigmoid(z3)\n",
    "\n",
    "        if y>0.5:\n",
    "            result=1\n",
    "        else:\n",
    "            result=0\n",
    "        \n",
    "        return y, result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 1 수행 결과\n",
    "#### 코드의 범용성을 높이기 위해 LogicGate 클래스를 초기화하는 생성자에 \n",
    "#### 은닉층의 Node 개수를 몇 개로 할 것인지 지정할 수 있도록 node_num이라는 argument를 추가했다.\n",
    "#### 이를 이용해 은닉층의 Node 개수가 10개인 XOR 게이트 객체를 만들어 수행한 결과는 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss val=  7.4366539774707014\n",
      "step=  0  loss value=  7.191899215739618\n",
      "step=  1000  loss value=  2.7489680423922884\n",
      "step=  2000  loss value=  2.7164909439995424\n",
      "step=  3000  loss value=  2.646896130347142\n",
      "step=  4000  loss value=  2.4947925178551578\n",
      "step=  5000  loss value=  2.225294202973984\n",
      "step=  6000  loss value=  1.8645018313024693\n",
      "step=  7000  loss value=  1.4310320617282453\n",
      "step=  8000  loss value=  1.0025543120906208\n",
      "step=  9000  loss value=  0.6870458316968849\n",
      "step=  10000  loss value=  0.4866385398247922\n",
      "step=  11000  loss value=  0.3610347182283913\n",
      "step=  12000  loss value=  0.2793882854020827\n",
      "step=  13000  loss value=  0.22380745735984642\n",
      "step=  14000  loss value=  0.18430882104030497\n",
      "step=  15000  loss value=  0.15518468977064376\n",
      "step=  16000  loss value=  0.13303609016411463\n",
      "step=  17000  loss value=  0.11575121571492958\n",
      "step=  18000  loss value=  0.10196539169977115\n",
      "step=  19000  loss value=  0.09076537026011275\n",
      "step=  20000  loss value=  0.08152097681904015\n"
     ]
    }
   ],
   "source": [
    "xdata=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "tdata=np.array([0,1,1,0])\n",
    "\n",
    "xor_obj=LogicGate(\"XOR\",xdata,tdata,10)\n",
    "xor_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0]  =  0\n",
      "[0 1]  =  1\n",
      "[1 0]  =  1\n",
      "[1 1]  =  0\n"
     ]
    }
   ],
   "source": [
    "test_data=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "for data in test_data:\n",
    "    (sigmoid_val,logical_val)=xor_obj.predict(data)\n",
    "    print(data,\" = \", logical_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제 2 \n",
    "### 1개의 은닉층에서 노드 1개를 설정할때 AND, OR, NAND, XOR 가운데 딥러닝 학습이 수행되지 않는 게이트는 무엇인가 ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AND 게이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss val=  3.106302618610198\n",
      "step=  0  loss value=  3.082663522905659\n",
      "step=  1000  loss value=  2.1782187732690157\n",
      "step=  2000  loss value=  1.721298952809574\n",
      "step=  3000  loss value=  1.091288857312153\n",
      "step=  4000  loss value=  0.625798135863854\n",
      "step=  5000  loss value=  0.3842293452091382\n",
      "step=  6000  loss value=  0.26139939442388266\n",
      "step=  7000  loss value=  0.1927355721169129\n",
      "step=  8000  loss value=  0.15048846939617383\n",
      "step=  9000  loss value=  0.12243067110602296\n",
      "step=  10000  loss value=  0.1026696737325607\n",
      "step=  11000  loss value=  0.08810516652463694\n",
      "step=  12000  loss value=  0.0769795940810565\n",
      "step=  13000  loss value=  0.06823335518688517\n",
      "step=  14000  loss value=  0.06119437064045008\n",
      "step=  15000  loss value=  0.05541797853176026\n",
      "step=  16000  loss value=  0.05059935700424224\n",
      "step=  17000  loss value=  0.04652315262828335\n",
      "step=  18000  loss value=  0.043033233089163264\n",
      "step=  19000  loss value=  0.04001383564923615\n",
      "step=  20000  loss value=  0.03737743125994879\n"
     ]
    }
   ],
   "source": [
    "xdata=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "and_ans=np.array([0,0,0,1])\n",
    "\n",
    "and_obj=LogicGate(\"AND\",xdata,and_ans,1)\n",
    "and_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0]  =  0\n",
      "[0 1]  =  0\n",
      "[1 0]  =  0\n",
      "[1 1]  =  1\n"
     ]
    }
   ],
   "source": [
    "test_data=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "\n",
    "for data in test_data:\n",
    "    (sigmoid_val,logical_val)=and_obj.predict(data)\n",
    "    print(data,\" = \", logical_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OR 게이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss val=  2.164355529138594\n",
      "step=  0  loss value=  2.1641013573272483\n",
      "step=  1000  loss value=  1.7587358814576164\n",
      "step=  2000  loss value=  0.9145882786973982\n",
      "step=  3000  loss value=  0.46795135347164707\n",
      "step=  4000  loss value=  0.2853619234399125\n",
      "step=  5000  loss value=  0.1983633317645666\n",
      "step=  6000  loss value=  0.14980874246427486\n",
      "step=  7000  loss value=  0.11946460473031165\n",
      "step=  8000  loss value=  0.09892629883938095\n",
      "step=  9000  loss value=  0.08419425120847317\n",
      "step=  10000  loss value=  0.07315485006402317\n",
      "step=  11000  loss value=  0.06459701998652632\n",
      "step=  12000  loss value=  0.05778123898600591\n",
      "step=  13000  loss value=  0.05223226316430489\n",
      "step=  14000  loss value=  0.047631648935324504\n",
      "step=  15000  loss value=  0.04375847083557501\n",
      "step=  16000  loss value=  0.04045489555906332\n",
      "step=  17000  loss value=  0.03760530211123219\n",
      "step=  18000  loss value=  0.03512313846651514\n",
      "step=  19000  loss value=  0.032942378250855164\n",
      "step=  20000  loss value=  0.031011809798459158\n"
     ]
    }
   ],
   "source": [
    "xdata=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "or_ans=np.array([0,1,1,1])\n",
    "\n",
    "or_obj=LogicGate(\"OR\",xdata,or_ans,1)\n",
    "or_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0]  =  0\n",
      "[0 1]  =  1\n",
      "[1 0]  =  1\n",
      "[1 1]  =  1\n"
     ]
    }
   ],
   "source": [
    "test_data=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "\n",
    "for data in test_data:\n",
    "    (sigmoid_val,logical_val)=or_obj.predict(data)\n",
    "    print(data,\" = \", logical_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NAND 게이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss val=  2.3115482091047506\n",
      "step=  0  loss value=  2.31093704464279\n",
      "step=  1000  loss value=  1.9844109289564267\n",
      "step=  2000  loss value=  1.360822002362593\n",
      "step=  3000  loss value=  0.7940546665991061\n",
      "step=  4000  loss value=  0.46786709184960135\n",
      "step=  5000  loss value=  0.30501342912416907\n",
      "step=  6000  loss value=  0.2179239237380657\n",
      "step=  7000  loss value=  0.16640158010225778\n",
      "step=  8000  loss value=  0.13321275446441558\n",
      "step=  9000  loss value=  0.11037933482140846\n",
      "step=  10000  loss value=  0.09385406652719108\n",
      "step=  11000  loss value=  0.08141145299990679\n",
      "step=  12000  loss value=  0.07174301245511225\n",
      "step=  13000  loss value=  0.06403582407341875\n",
      "step=  14000  loss value=  0.05776125436528211\n",
      "step=  15000  loss value=  0.052562157616975455\n",
      "step=  16000  loss value=  0.048189326389966085\n",
      "step=  17000  loss value=  0.04446400387378478\n",
      "step=  18000  loss value=  0.04125487680992093\n",
      "step=  19000  loss value=  0.03846346199888354\n",
      "step=  20000  loss value=  0.03601454125170121\n"
     ]
    }
   ],
   "source": [
    "xdata=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "nand_ans=np.array([1,1,1,0])\n",
    "\n",
    "nand_obj=LogicGate(\"NAND\",xdata,nand_ans,1)\n",
    "nand_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0]  =  1\n",
      "[0 1]  =  1\n",
      "[1 0]  =  1\n",
      "[1 1]  =  0\n"
     ]
    }
   ],
   "source": [
    "test_data=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "\n",
    "for data in test_data:\n",
    "    (sigmoid_val,logical_val)=nand_obj.predict(data)\n",
    "    print(data,\" = \", logical_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XOR 게이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss val=  3.096385322244129\n",
      "step=  0  loss value=  3.0878091917712602\n",
      "step=  1000  loss value=  2.7724982964978993\n",
      "step=  2000  loss value=  2.772460305519719\n",
      "step=  3000  loss value=  2.772412535679506\n",
      "step=  4000  loss value=  2.7723415003518883\n",
      "step=  5000  loss value=  2.772225817315729\n",
      "step=  6000  loss value=  2.7720268900195997\n",
      "step=  7000  loss value=  2.7716688758365344\n",
      "step=  8000  loss value=  2.770991405327651\n",
      "step=  9000  loss value=  2.7696293762295365\n",
      "step=  10000  loss value=  2.7666913270700535\n",
      "step=  11000  loss value=  2.7599097620368767\n",
      "step=  12000  loss value=  2.743757914647632\n",
      "step=  13000  loss value=  2.706923556136457\n",
      "step=  14000  loss value=  2.6316059880543055\n",
      "step=  15000  loss value=  2.5051636052205355\n",
      "step=  16000  loss value=  2.357059543143464\n",
      "step=  17000  loss value=  2.235856340369711\n",
      "step=  18000  loss value=  2.1529275705523694\n",
      "step=  19000  loss value=  2.0981265050833953\n",
      "step=  20000  loss value=  2.0610300117317575\n"
     ]
    }
   ],
   "source": [
    "xdata=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "xor_ans=np.array([0,1,1,0])\n",
    "\n",
    "xor_obj=LogicGate(\"XOR\",xdata,xor_ans,1)\n",
    "xor_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0]  =  0\n",
      "[0 1]  =  1\n",
      "[1 0]  =  1\n",
      "[1 1]  =  1\n"
     ]
    }
   ],
   "source": [
    "test_data=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "\n",
    "for data in test_data:\n",
    "    (sigmoid_val,logical_val)=xor_obj.predict(data)\n",
    "    print(data,\" = \", logical_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 2 수행 결과\n",
    "#### 출력된 결과에서 확인할 수 있듯, 은닉층의 Node 개수가 1개일 경우 XOR 게이트에서의 예측값이 우리가 기대한 값과는 전혀 다른 값이 출력되었다.\n",
    "#### 따라서 XOR 게이트에서 딥러닝 학습이 제대로 이뤄지지 않음을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9e822bff7004e02754f0025fb6c0b6cc8ebdd971e90d87dc63a4bec712004caf"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
